{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2707304",
   "metadata": {},
   "source": [
    "Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c35936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import timm\n",
    "import matplotlib.pyplot as plt\n",
    "import torchtext\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bbc1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(59)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb2e02e",
   "metadata": {},
   "source": [
    "# Split traninng dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a8397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train data\n",
    "train_data = []\n",
    "train_set_path = './vaq2.0.TrainImages.txt'\n",
    "\n",
    "with open(train_set_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        temp = line.split('\\t')\n",
    "        qa = temp[1].split('?')\n",
    "        if len(qa) == 3:\n",
    "            answer = qa[2].strip()\n",
    "        else:\n",
    "            answer = qa[1].strip()\n",
    "\n",
    "        data_sample = {\n",
    "            'image_path': temp[0][:-2],\n",
    "            'question': qa[0] + '?',\n",
    "            'answer': answer\n",
    "        }\n",
    "\n",
    "        train_data.append(data_sample)\n",
    "\n",
    "# load val data\n",
    "val_data = []\n",
    "val_set_path = './vaq2.0.DevImages.txt'\n",
    "\n",
    "with open(val_set_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        temp = line.split('\\t')\n",
    "        qa = temp[1].split('?')\n",
    "\n",
    "        if len(qa) == 3:\n",
    "            answer = qa[2].strip()\n",
    "        else:\n",
    "            answer = qa[1].strip()\n",
    "\n",
    "        data_sample = {\n",
    "            'image_path': temp[0][:-2],\n",
    "            'question': qa[0] + '?',\n",
    "            'answer': answer\n",
    "        }\n",
    "        val_data.append(data_sample)\n",
    "\n",
    "# load test data\n",
    "test_data = []\n",
    "test_set_path = './vaq2.0.TestImages.txt'\n",
    "\n",
    "with open(val_set_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        temp = line.split('\\t')\n",
    "        qa = temp[1].split('?')\n",
    "\n",
    "        if len(qa) == 3:\n",
    "            answer = qa[2].strip()\n",
    "        else:\n",
    "            answer = qa[1].strip()\n",
    "\n",
    "        data_sample = {\n",
    "            'image_path': temp[0][:-2],\n",
    "            'question': qa[0] + '?',\n",
    "            'answer': answer\n",
    "        }\n",
    "        test_data.append(data_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62df9fa7",
   "metadata": {},
   "source": [
    "# Build vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7f6429",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def get_tokens(data_iter):\n",
    "    for sample in data_iter:\n",
    "        question = sample['question']\n",
    "        yield [token.text for token in eng.tokenizer(question)]\n",
    "\n",
    "vocab = build_vocab_from_iterator(\n",
    "    get_tokens(train_data),\n",
    "    min_freq=2,\n",
    "    specials=['<pad>', '<sos>', '<eos>', '<unk>'],\n",
    "    special_first=True\n",
    ")\n",
    "\n",
    "vocab.set_default_index(vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a5187d",
   "metadata": {},
   "source": [
    "# Build dictionary mapping classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb15e81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = set([sample['answer'] for sample in train_data])\n",
    "\n",
    "label2idx = {\n",
    "    cls_name: idx for idx, cls_name in enumerate(classes)\n",
    "}\n",
    "\n",
    "idx2label = {\n",
    "    idx: cls_name for idx, cls_name in enumerate(classes)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e276003a",
   "metadata": {},
   "source": [
    "# Build tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542037f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(question, max_seq_len):\n",
    "    tokens = [token.text for token in eng.tokenizer(question)]\n",
    "    sequence = [vocab[token] for token in tokens]\n",
    "    if len(sequence) < max_seq_len:\n",
    "        sequence += [vocab['<pad>']]*(max_seq_len - len(sequence))\n",
    "    else:\n",
    "        sequence = sequence[:max_seq_len]\n",
    "\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78e46cd",
   "metadata": {},
   "source": [
    "Build data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c912099",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQADataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 data,\n",
    "                 label2idx,\n",
    "                 max_seq_len = 20,\n",
    "                 transform=None,\n",
    "                 img_dir='val2014-resized/'):\n",
    "        self.transform = transform\n",
    "        self.data = data\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.img_dir = img_dir\n",
    "        self.label2idx = label2idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.img_dir, self.data[index]['image_path'])\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        question = self.data[index]['question']\n",
    "        question = tokenize(question, self.max_seq_len)\n",
    "        question = torch.tensor(question, dtype=torch.long)\n",
    "\n",
    "        label = self.data[index]['answer']\n",
    "        label = label2idx[label]\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return img, question, label\n",
    "    \n",
    "# data transform\n",
    "data_transform = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(size=(224, 224)),\n",
    "        transforms.CenterCrop(size=180),\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.GaussianBlur(3),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(size=(224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Define dataset\n",
    "train_dataset = VQADataset(\n",
    "    train_data,\n",
    "    label2idx=label2idx,\n",
    "    transform=data_transform['train']\n",
    ")\n",
    "\n",
    "val_dataset = VQADataset(\n",
    "    val_data,\n",
    "    label2idx=label2idx,\n",
    "    transform=data_transform['val']\n",
    ")\n",
    "\n",
    "test_dataset = VQADataset(\n",
    "    test_data,\n",
    "    label2idx=label2idx,\n",
    "    transform=data_transform['val']\n",
    ")\n",
    "\n",
    "# data loader\n",
    "train_batch_size = 256,\n",
    "test_batch_size = 32,\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=train_batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=test_batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=test_batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960ee1ae",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a39fb08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VQA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
